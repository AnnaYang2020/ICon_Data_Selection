<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ICon: In-Context Contribution for Automatic Data Selection</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ICon: In-Context Contribution for <br> Automatic Data Selection</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Yixin Yang,</span>
                <span class="author-block">
                  Qingxiu Dong,</span>
                  <span class="author-block">
                    Linli Yao,</span>
                  <span class="author-block">
                    Fangwei Zhu,</span>
                  <span class="author-block">
                    Zhifang Sui
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Peking Univercity<br>yangyx@stu.pku.edu.cn</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/Figure_3.png" alt="Figure 3" style="width: 100%;">
      <h2 class="subtitle has-text-left" style="font-size: 1.1rem; line-height: 1.6; margin-top: 1.5rem; color: #333; font-weight: normal;">
        Instruction tuning is critical for improving LLMs, and effective data selection enhances its performance while reducing computational cost. We present <b>I</b>n-<b>co</b>ntext Learning for <b>Co</b>ntribution Measurement (ICon), a gradient-free, bias-reduced method that leverages in-context learning to measure the contribution of individual samples. ICon enables efficient identification of high-contribution data, improving overall model performance with fewer samples.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Data selection for instruction tuning is essential for improving the performance of Large Language Models (LLMs) and reducing training cost. However, existing automated selection methods either depend on computationally expensive gradient-based measures or manually designed heuristics, which may fail to fully exploit the intrinsic attributes of data and model. In this paper, we propose In-context Learning for Contribution Measurement (ICon), a novel gradient-free method that takes advantage of the implicit fine-tuning nature of in-context learning (ICL) to measure sample contribution without gradient computation or manual indicators engineering. Compared to gradient-based methods, ICon greatly reduces computational cost; compared to heuristic methods, it minimizes human inductive bias. Our method consists of three components: an assessment set to provide a performance reference, ICon scores to quantify sample contribution, and a lightweight selection paradigm for scalable data selection. Extensive experiments on three LLMs across 12 benchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of ICon. For example, on LLaMA3.1-8B, models trained on 15% of ICon-selected data outperform full datasets by 5.42 percentage points and exceed the best performance of widely used selection methods by 2.06 percentage points. Our analysis further investigates the effects of data scale, generalization across datasets, and the characteristics of high-contribution samples selected by ICon.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Introduction -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Introduction</h2>
      <div class="content has-text-justified" style="font-size: 1.1rem; line-height: 1.6; color: #333;">
        <p>
          Recent advances in LLMs have shown that instruction tuning effectively improves model performance, typically relying on large-scale datasets. However, studies suggest that carefully selecting high-quality subsets can achieve better results at lower computational cost. Existing automated data selection methods either depend on gradient-based measures, which are computationally expensive, or on manually designed heuristics, which often fail to capture true sample contribution and may introduce human inductive bias.
        </p>
        <p>
          We propose <b>I</b>n-<b>Con</b>text Learning for <b>Con</b>tribution Measurement (ICon), a novel data selection method that estimates sample contribution without gradients or manual heuristics by leveraging the implicit fine-tuning property of in-context learning (ICL). <b>ICon consists of three components: an assessment set, a contribution score computed via ICL, and a lightweight selection model trained with LoRA to enable scalable, linear-complexity inference calls.</b> Compared to gradient-based methods, ICon greatly reduces computational overhead; compared to heuristic-based methods, it more effectively identifies high-contribution data for instruction tuning.
        </p>
        <p>
          The main contributions of our paper are as follows:
        </p>
        <ol>
          <li>We propose ICon, a novel data selection method inspired by ICL. By leveraging its implicit fine-tuning nature, ICon enables gradient-free and bias-reduced measurement of each sample's contribution to model performance.</li>
          <li>Our approach avoids gradient updates and auxiliary models, reducing computational cost and design complexity. Once trained with LoRA, the ICon-guided selection paradigm enables data selection through linear-complexity inference calls, making it highly scalable.</li>
          <li>We demonstrate the effectiveness of ICon through experiments on multiple models, 12 widely used benchmarks, and 5 pairwise test sets, showing consistent performance gains over baselines.</li>
        </ol>
      </div>
    </div>
  </div>
</section>
<!-- End Introduction -->

<!-- Results -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Results</h2>
      <div class="columns" style="margin-bottom: 2rem;">
        <div class="column is-6" style="overflow: visible;">
          <div style="width: 150%; margin-left: 0%;">
            <img src="static/images/Figure_6.png" alt="Figure 6" style="width: 100%;">
          </div>
        </div>
        <div class="column is-6" style="overflow: visible;">
          <div style="width: 100%; margin-left: 45%;">
            <img src="static/images/Figure_7.png" alt="Figure 7" style="width: 55.65%;">
          </div>
        </div>
      </div>
      <div class="columns">
        <div class="column is-7">
          <div class="content has-text-justified" style="font-size: 1.1rem; line-height: 1.6; color: #333;">
            <p>
              We demonstrate the effectiveness of ICon across multiple models and evaluation settings. Experiments on LLaMA3.1-8B, Qwen2.5-3B, and LLaMA2-7B are conducted using 12 widely used benchmarks and 5 pairwise comparison test sets.
            </p>
            <p>
              <b>Models trained on a small fraction of ICon-selected data outperform their full-data counterparts.</b> With only 15% of the data, LLaMA3.1-8B and Qwen2.5-3B improve by 5.42 and 1.24 percentage points in average benchmark scores, respectively; LLaMA2-7B achieves a 0.65-point gain using just 5%. In pairwise comparison, we evaluate the strongest models from benchmark results: LLaMA3.1-8B, Qwen2.5-3B, and LLaMA2-7B, trained on 7,800, 7,800, and 520 ICon-selected samples, respectively. All three consistently outperform their full-data counterparts across all five test sets.
            </p>
            <p>
              <b>ICon also surpasses widely used selection methods.</b> For example, it improves LLaMA3.1-8B's average benchmark score by 2.06 points over the best baseline. In pairwise comparison, ICon shows consistent and clear advantages over the widely used selection methods across all test sets and in overall performance.
            </p>
          </div>
        </div>
        <div class="column is-5">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <img src="static/images/Figure_8.png" alt="Figure 8" style="width: 85%; margin-left: 7%;"/>
            </div>
            <div class="item">
              <img src="static/images/Figure_9-3.png" alt="Figure 9-3" style="width: 85%; margin-left: 7%;"/>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Results -->

<!-- Analysis -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Analysis</h2>
      <div id="analysis-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/Figure_10.png" alt="Figure 10" style="width: 35%; margin-left: 32.5%;"/>
        </div>
        <div class="item">
          <img src="static/images/Figure_11.png" alt="Figure 11" style="width: 35%; margin-left: 32.5%;"/>
        </div>
        <div class="item">
          <img src="static/images/Figure_12.png" alt="Figure 12" style="width: 35%; margin-left: 32.5%;"/>
        </div>
        <div class="item">
          <img src="static/images/Figure_13.png" alt="Figure 13" style="width: 35%; margin-left: 32.5%;"/>
        </div>
      </div>
      <div class="content has-text-justified" style="font-size: 1.1rem; line-height: 1.6; color: #333; margin-top: 2rem;">
        <p>
          <b>Optimal Data Scale:</b> We examine how data scale affects instruction tuning performance using LLaMA3.1-8B. The results exhibit a general trend of rising and then falling performance, with the average benchmark score peaking at 15% of ICon-selected dataâ€”outperforming models trained on larger subsets.
        </p>
        <p>
          <b>Generalization on different Datasets:</b> To evaluate generalization, we apply the Alpaca-trained selection paradigm to the WizardLM dataset. The model trained on just 5% of WizardLM achieves the best performance, with a 4.54-point gain over the full dataset, confirming ICon's effectiveness across datasets without retraining the selection model.
        </p>
        <p>
          <b>Characteristics of Selected Samples:</b> t-SNE analysis reveals that high-contribution samples are both diverse and locally clustered. These samples are generally more difficult than the full dataset, but not skewed toward the highest difficulty, suggesting that ICon favors appropriately challenging data while avoiding extremes.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Analysis -->

<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Conclusion</h2>

      <div class="content has-text-justified" style="font-size: 1.1rem; line-height: 1.6; color: #333; margin-top: 2rem;">
        In this work, we introduced ICon, a novel method that uses ICL to efficiently assess the contribution of individual training samples without human inductive bias. The method is structured into three stages: constructing an assessment set, computing ICon scores, and training a lightweight selection paradigm for scalable data selection. Extensive experiments on three LLMs across 12 benchmarks and 5 pairwise evaluation sets show that models trained on ICon-selected data outperform those trained on the full dataset, achieving superior performance with fewer samples. ICon also significantly outperforms other widely used data selection methods. We further analyzed the optimal data scale, generalization across datasets, and characteristics of high-contribution samples. As data scale increases, performance improves initially but later declines, indicating an optimal data size. ICon generalizes well across datasets, and its high-contribution samples display diversity while maintaining an appropriate level of difficulty for effective learning.
      </div>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
